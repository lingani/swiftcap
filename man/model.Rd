% Generated by roxygen2 (4.0.2): do not edit by hand
\docType{data}
\name{model}
\alias{model}
\title{Basic N-Gram Model}
\format{\preformatted{List of 4
 $ ngrams     :Classes ‘data.table’ and 'data.frame':	1235227 obs. of  5 variables:
  ..$ context: chr [1:1235227] "" "" "" "" ...
  ..$ word   : chr [1:1235227] "the" "to" "and" "a" ...
  ..$ n      : num [1:1235227] 1 1 1 1 1 2 2 2 2 2 ...
  ..$ p      : num [1:1235227] 0.0392 0.0227 0.0199 0.0198 0.0165 ...
  ..$ rank   : int [1:1235227] 1 2 3 4 5 1 2 3 4 5 ...
  ..- attr(*, ".internal.selfref")=<externalptr> 
  ..- attr(*, "index")= atomic (0) 
  .. ..- attr(*, "context")= int(0) 
 $ N          : int [1:3] 1 2 3
 $ freq_cutoff: num 3
 $ rank_cutoff: num 5
 - attr(*, "class")= chr "ngram"
}}
\usage{
model
}
\description{
An N-Gram language model that uses the Katz Back-off Algorithm across trigram,
bigram and unigram sub-models.
}
\details{
The model was built on a 75% random sample of a large data set of text culled
from Twitter, online blogs, and news articles.  All n-grams occurring less
than 3 times were removed and only the top 5 suggestions for each context
have been retained.
}
\keyword{datasets}

